{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for problem 2. You may reuse your SGD code from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function may be useful for loading the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SGD code I wrote in week 1's set, but with modifications to the loss/gradient function\n",
    "# to account for regularization\n",
    "def loss(X, Y, w):\n",
    "    '''\n",
    "    Calculate the error. The regularization term is not included in calculating the normal error.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "        lam: the value of lambda\n",
    "    \n",
    "    Outputs:\n",
    "        l: The loss evaluated with respect to X, Y, w, and lambda\n",
    "    '''\n",
    "    loss = 0 \n",
    "    for i in range(0, len(X)):\n",
    "        loss += np.log(1/(1 + np.exp(-Y[i] * np.dot(w, X[i]))))\n",
    "    return loss \n",
    "\n",
    "def gradient(x, y, w, lam, N):\n",
    "    '''\n",
    "    Calculate the gradient of the loss function with respect to\n",
    "    a single point (x, y), and using weight vector w for the regularized\n",
    "    logistic loss function. \n",
    "    \n",
    "    Inputs:\n",
    "        x: A (D, ) shaped numpy array containing a single data point.\n",
    "        y: The float label for the data point.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "        lam: a float value for lambda\n",
    "        N: the total number of points\n",
    "        \n",
    "    Output:\n",
    "        g: The gradient of the loss with respect to x, y, and w. \n",
    "    '''\n",
    "    reg_factor = w * (lam / N) \n",
    "    gradient = (1 / (1 + np.exp(-1 * np.dot(w, x))) - y) * x\n",
    "    return gradient - reg_factor\n",
    "\n",
    "    \n",
    "\n",
    "def SGD(X, Y, w_start, eta, lam, N_epochs):\n",
    "    '''\n",
    "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
    "    learning rate eta, and N_epochs epochs.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
    "        eta: The step size.\n",
    "        lam: the regularization lambda\n",
    "        N_epochs: The number of epochs (iterations) to run SGD.\n",
    "        \n",
    "    Outputs:\n",
    "        W: A (N_epochs, D) shaped array containing the weight vectors from all iterations.\n",
    "        Ein: The training error using the final w\n",
    "    '''\n",
    "    \n",
    "    losses = []\n",
    "    W = []\n",
    "    old_w = w_start\n",
    "    for i in range(0, N_epochs):\n",
    "        p = np.random.permutation(len(X))\n",
    "        for j in range(0, len(X)):\n",
    "            new_w = old_w - eta * gradient(X[p[j]], Y[p[j]], old_w, lam, len(X))\n",
    "            old_w = new_w\n",
    "    return new_w, loss(X, Y, new_w)\n",
    "\n",
    "def random_w(length):\n",
    "    w = []\n",
    "    for i in range(0, length):\n",
    "        w.append(np.random.ranf())\n",
    "    return np.array(w)\n",
    "\n",
    "# Adjust each of the N points to be normalized, \n",
    "def normalize(X):\n",
    "    # First rearrange values such that we can find the mean/std deviation of each column\n",
    "    rearranged_vals = []\n",
    "    for j in range(0, len(X[0])):\n",
    "        col = []\n",
    "        for i in range(0, len(X)):\n",
    "            col.append(X[i][j])\n",
    "        rearranged_vals.append(col)\n",
    "    \n",
    "    # Now adjust values\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, len(X[0])):\n",
    "            X[i][j] = (X[i][j] - np.mean(rearranged_vals[j])) / np.std(rearranged_vals[j])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the lambda array\n",
    "lambdas = []\n",
    "lam = .00001\n",
    "for i in range(0, 15):\n",
    "    lambdas.append(lam)\n",
    "    lam *= 5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load_data('data/wine_training1.txt')\n",
    "X1 = data1[:, 1:]\n",
    "Y1 = data1[:, 0]\n",
    "\n",
    "data2 = load_data('data/wine_training2.txt')\n",
    "X2 = data2[:, 1:]\n",
    "Y2 = data2[:, 0]\n",
    "\n",
    "data_test = load_data('data/wine_testing.txt')\n",
    "X_test = data_test[:, 1:]\n",
    "Y_test = data_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of X arrays\n",
    "X1 = normalize(X1)\n",
    "X2 = normalize(X2)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amyz7\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\amyz7\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\amyz7\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\users\\amyz7\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:67: RuntimeWarning: overflow encountered in subtract\n",
      "c:\\users\\amyz7\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: overflow encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "Ein_1 = []\n",
    "Ein_2 = []\n",
    "\n",
    "Eout_1 = []\n",
    "Eout_2 = []\n",
    "\n",
    "l2_norm_1 = []\n",
    "l2_norm_2 = []\n",
    "\n",
    "for i in range(0, 15):\n",
    "    start_w = random_w(13)\n",
    "    W1, ein1 = SGD(X1, Y1, start_w, 5 * np.exp(-4), lambdas[i], 20000)\n",
    "    W2, ein2 = SGD(X2, Y2, start_w, 5 * np.exp(-4), lambdas[i], 20000)\n",
    "    eout1 = loss(X_test, Y_test, W1)\n",
    "    eout2 = loss(X_test, Y_test, W2)\n",
    "    Ein_1.append(ein1)\n",
    "    Ein_2.append(ein2)\n",
    "    \n",
    "    Eout_1.append(eout1)\n",
    "    Eout_1.append(eout2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
